{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SD2GAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imnawar/SD2GAN/blob/main/SD2GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrOG-k_2fk3m"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1D6vfbTYhH8"
      },
      "source": [
        "class SD2GAN():\n",
        "    def __init__(self, **params):\n",
        "        self.img_rows = 28\n",
        "        self.img_cols = 28\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.latent_dim = params['z_dim']\n",
        "        self.dataset = params['dataset']\n",
        "        self.batch_size = params['bs']\n",
        "        self.epochs = params['epochs']\n",
        "\n",
        "        self.optimizer1 = tf.keras.optimizers.Adam(params['lr'], params['beta'])\n",
        "        self.optimizer2 = tf.keras.optimizers.Adam(params['lr_disc2'], params['beta'])\n",
        "\n",
        "        if self.dataset == 'mnist': \n",
        "            self.PATH = 'SD2GAN' + '/' + self.dataset +'/' + 'SN'\n",
        "            (self.x_train, self.y_train), (self.x_test, self.y_test) = tf.keras.datasets.mnist.load_data()\n",
        "            self.x_train = self.x_train / 127.5 - 1.\n",
        "            self.x_test = self.x_test / 127.5 - 1.\n",
        "            self.img_rows = self.x_train.shape[1]\n",
        "            self.img_cols = self.x_train.shape[2]\n",
        "            self.channels = 1\n",
        "            self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        elif self.dataset == 'fashion':\n",
        "            self.PATH = 'SD2GAN' + '/' + self.dataset +'/' + 'SN'\n",
        "            (self.x_train, self.y_train), (self.x_test, self.y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "            self.x_train = self.x_train / 127.5 - 1.\n",
        "            self.x_test = self.x_test / 127.5 - 1.\n",
        "            self.img_rows = self.x_train.shape[1]\n",
        "            self.img_cols = self.x_train.shape[2]\n",
        "            self.channels = 1\n",
        "            self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "\n",
        "        json_file = open(self.PATH + '.json', 'r')\n",
        "        loaded_model_json = json_file.read()\n",
        "        json_file.close()\n",
        "        self.Siamese_net = tf.keras.models.model_from_json(loaded_model_json)\n",
        "        self.Siamese_net.load_weights(self.PATH + '.h5')\n",
        "\n",
        "\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy', optimizer=self.optimizer1, metrics=['accuracy'])\n",
        "\n",
        "        self.discriminator2 = self.build_discriminator2()\n",
        "        self.discriminator2.compile(loss='binary_crossentropy', optimizer=self.optimizer2, metrics=['accuracy'])\n",
        "\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        z = tf.keras.layers.Input(shape=(self.latent_dim,))\n",
        "        img = self.generator(z)\n",
        "        imgs1 = tf.keras.layers.Input((self.img_shape))\n",
        "        imgs2 = tf.keras.layers.Input(self.img_shape)\n",
        "        self.discriminator.trainable = False\n",
        "        self.discriminator2.trainable = False\n",
        "        self.Siamese_net.trainable = False\n",
        "        similarity = self.Siamese_net([imgs1, imgs2])\n",
        "        similarity_validity = self.discriminator2(similarity)\n",
        "        validity = self.discriminator(img)\n",
        "\n",
        "        self.combined = tf.keras.models.Model([z, [imgs1, imgs2]], [validity, similarity_validity])\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=self.optimizer1)\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = tf.keras.models.Sequential()\n",
        "        model.add(tf.keras.layers.Dense((128*7*7), input_shape=(self.latent_dim,)))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation('tanh'))\n",
        "        model.add(tf.keras.layers.Reshape((7, 7, 128)))\n",
        "        model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n",
        "        model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same'))\n",
        "        model.add(tf.keras.layers.Activation('tanh'))\n",
        "        model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n",
        "        model.add(tf.keras.layers.Conv2D(1, (5, 5), padding='same'))\n",
        "        model.add(tf.keras.layers.Activation('tanh'))\n",
        "\n",
        "        noise = tf.keras.layers.Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        return tf.keras.models.Model(noise, img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        model = tf.keras.models.Sequential()\n",
        "        model.add(tf.keras.layers.Conv2D(128, (5, 5),padding='same', input_shape=self.img_shape))\n",
        "        model.add(tf.keras.layers.Activation('tanh'))\n",
        "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        model.add(tf.keras.layers.Dense(512))\n",
        "        model.add(tf.keras.layers.Activation('tanh'))\n",
        "        model.add(tf.keras.layers.Dense(1))\n",
        "        model.add(tf.keras.layers.Activation('sigmoid'))\n",
        "\n",
        "        img = tf.keras.layers.Input(shape=self.img_shape,)\n",
        "        validity = model(img)\n",
        "\n",
        "        return tf.keras.models.Model(img, validity)\n",
        "\n",
        "    def build_discriminator2(self):\n",
        "\n",
        "        model = tf.keras.models.Sequential()\n",
        "        model.add(tf.keras.layers.Dense(128, input_shape=(1,), activation=tf.nn.relu))\n",
        "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "        array_sim = tf.keras.layers.Input(shape=(1,))\n",
        "        validity = model(array_sim)\n",
        "\n",
        "        return tf.keras.models.Model(array_sim, validity)\n",
        "\n",
        "    def train(self):\n",
        "        start_time = time.time()\n",
        "        valid = np.ones((self.batch_size, 1))\n",
        "        fake = np.zeros((self.batch_size, 1))\n",
        "        fake_s = np.zeros((int(self.batch_size/2), 1))\n",
        "        real_s = np.ones((int(self.batch_size/2), 1))\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "\n",
        "            idx = np.random.randint(0, self.x_train.shape[0], self.batch_size)\n",
        "            imgs = self.x_train[idx]\n",
        "            noise = np.random.normal(0, 1, (self.batch_size, self.latent_dim))\n",
        "\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "            splited_batch_real = np.split(imgs, 2)\n",
        "            part1_real = splited_batch_real[0]\n",
        "            part2_real = splited_batch_real[1]\n",
        "            sim_real = self.Siamese_net.predict([part1_real, part2_real])\n",
        "\n",
        "            noise2 = np.random.normal(0, 1, (self.batch_size, self.latent_dim))\n",
        "            gen_imgs2 = self.generator.predict(noise2)\n",
        "\n",
        "            splited_batch = np.split(gen_imgs2, 2)\n",
        "            part1 = splited_batch[0]\n",
        "            part2 = splited_batch[1]\n",
        "\n",
        "            sim_fake = self.Siamese_net.predict([part1, part2])\n",
        "            \n",
        "\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            d_loss_real2 = self.discriminator2.train_on_batch(sim_real, real_s)\n",
        "            d_loss_fake2 = self.discriminator2.train_on_batch(sim_fake, fake_s)\n",
        "            d_loss2 = 0.5 * np.add(d_loss_real2, d_loss_fake2)\n",
        "\n",
        "            noise = np.random.normal(0, 1, (self.batch_size, self.latent_dim))\n",
        "            noise2 = np.random.normal(0, 1, (self.batch_size*2, self.latent_dim))\n",
        "            gen_imgs2 = self.generator.predict(noise2)\n",
        "            g_loss = self.combined.train_on_batch([noise, [gen_imgs2[:self.batch_size,:,:,:], gen_imgs2[self.batch_size:,:,:,:]]], valid)\n",
        "\n",
        "            if epoch % 1500 == 0:\n",
        "                print (\"%d [D loss: %f, acc.: %.2f%%] [D2 loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], d_loss2[0], 100*d_loss2[1], g_loss[0]))\n",
        "\n",
        "        print(\"Training done in: %s minutes ---\" % ((time.time() - start_time)/60))\n",
        "\n",
        "        model_json = self.generator.to_json()\n",
        "        with open(\"output/generator.json\", \"w\") as json_file:\n",
        "            json_file.write(model_json)\n",
        "        self.generator.save_weights(\"output/generator.h5\")\n",
        "        print(\"Saved Generator to output/\")\n",
        "        r, c = 8, 8\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"output/%d.png\" % epoch)\n",
        "        plt.close()\n",
        "        print(\"Saved generated imgs to output/\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24WZcy32zdOA",
        "outputId": "a5d02c6e-f22b-49b0-8883-c2df6f4e4f85"
      },
      "source": [
        "'''\n",
        "    Setup settings and download all necessary files\n",
        "'''\n",
        "# Download pre-trained models \n",
        "!wget -O SD2GAN.zip https://www.dropbox.com/s/4ez4oqbo6sw8oex/SD2GAN.zip?dl=0\n",
        "# Unzip the files \n",
        "fantasy_zip = zipfile.ZipFile('SD2GAN.zip')\n",
        "fantasy_zip.extractall('')\n",
        "fantasy_zip.close()\n",
        "#Setup arguments\n",
        "params = {\n",
        "    'dataset': \"mnist\", # 'mnist' , 'fashion'\n",
        "    'train' : False, \n",
        "    'pretrained': \"SD2GAN\", \n",
        "    'z_dim' : 100, \n",
        "    'lr' : 0.0001, \n",
        "    'lr_disc2' : 0.00009, \n",
        "    'beta' : 0.5, \n",
        "    'bs' : 32, \n",
        "    'epochs' : 30000\n",
        "}\n",
        "# Making output folder\n",
        "try: os.mkdir('output')\n",
        "except: pass\n",
        "if params['train']:\n",
        "    gan = SD2GAN(**params)\n",
        "    gan.train()\n",
        "else:\n",
        "  gan = params['pretrained']\n",
        "  dataset = params['dataset']\n",
        "  latent_dim = params['z_dim']\n",
        "  PATH = 'SD2GAN/' + dataset +'/'+ gan\n",
        "  # Load the pretrained model\n",
        "  json_file = open(PATH+\".json\", 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  G = tf.keras.models.model_from_json(loaded_model_json)\n",
        "  G.load_weights(PATH+\".h5\")\n",
        "  print(\"Loaded Generator from disk. \", gan)\n",
        "  print(\"Generating image\")\n",
        "  noise = np.random.normal(0, 1, (1, latent_dim))\n",
        "  gen_imgs = G.predict(noise)\n",
        "  plt.imshow(gen_imgs[0,:,:,0], cmap='gray')\n",
        "  plt.savefig(\"output/%d.png\" % 1)\n",
        "  plt.close()\n",
        "  print(\"you can find the output in output/ folder.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-07 19:04:56--  https://www.dropbox.com/s/4ez4oqbo6sw8oex/SD2GAN.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:601a:18::a27d:712\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/4ez4oqbo6sw8oex/SD2GAN.zip [following]\n",
            "--2021-05-07 19:04:57--  https://www.dropbox.com/s/raw/4ez4oqbo6sw8oex/SD2GAN.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc5813019f60b40cea4242020b8c.dl.dropboxusercontent.com/cd/0/inline/BODbiRldX2Bpla-lPRRVU-DBrqUHI0DwK5TQdlvDtdHIFlJO3JnVcnJ-IBnL1pEenjSO98QWoELcqp8Zka-hTC8j9ZBCG18scCmtVG3L5sPPKwFJZxHpZKDS-bAa-1pmxOjg--c8KtpPm3R4PopWb8_R/file# [following]\n",
            "--2021-05-07 19:04:57--  https://uc5813019f60b40cea4242020b8c.dl.dropboxusercontent.com/cd/0/inline/BODbiRldX2Bpla-lPRRVU-DBrqUHI0DwK5TQdlvDtdHIFlJO3JnVcnJ-IBnL1pEenjSO98QWoELcqp8Zka-hTC8j9ZBCG18scCmtVG3L5sPPKwFJZxHpZKDS-bAa-1pmxOjg--c8KtpPm3R4PopWb8_R/file\n",
            "Resolving uc5813019f60b40cea4242020b8c.dl.dropboxusercontent.com (uc5813019f60b40cea4242020b8c.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n",
            "Connecting to uc5813019f60b40cea4242020b8c.dl.dropboxusercontent.com (uc5813019f60b40cea4242020b8c.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BOCplCbUOd9QuG4PFUKTJgp4RX7N_1L3Xa85uQm5JFcSLCD7MVRZ6arlxKTShySt5yTBtbBE_rvZtfF9vPRB1bu3RWO4Q9Fcz8O2b5-f6sTFGPcSkYLRdwYjKxiMmZSceXtYBmS3fwzHfMH9KGGS3DIs_hmJwFZWxlme_QLwFtxfQlfvzADj6cqsNfSHKqySW-pV-6UCyB0knwHGHz5RNjuttvruWSWUwBZTkf_z3IS5K-Vnu15zFnqx8TQmAjAv_s-1JkboHuersXj29QHvdIEjq8KROhRe9UD42qwjV8rX6hvM7iUOLfMDqt4gOXP-NfGIbKuzqOnPdLQhNpCOhweFLCwntEACB4zOeR4IqC-pKzSGZUD9trsoSMFAMT-08lo/file [following]\n",
            "--2021-05-07 19:04:57--  https://uc5813019f60b40cea4242020b8c.dl.dropboxusercontent.com/cd/0/inline2/BOCplCbUOd9QuG4PFUKTJgp4RX7N_1L3Xa85uQm5JFcSLCD7MVRZ6arlxKTShySt5yTBtbBE_rvZtfF9vPRB1bu3RWO4Q9Fcz8O2b5-f6sTFGPcSkYLRdwYjKxiMmZSceXtYBmS3fwzHfMH9KGGS3DIs_hmJwFZWxlme_QLwFtxfQlfvzADj6cqsNfSHKqySW-pV-6UCyB0knwHGHz5RNjuttvruWSWUwBZTkf_z3IS5K-Vnu15zFnqx8TQmAjAv_s-1JkboHuersXj29QHvdIEjq8KROhRe9UD42qwjV8rX6hvM7iUOLfMDqt4gOXP-NfGIbKuzqOnPdLQhNpCOhweFLCwntEACB4zOeR4IqC-pKzSGZUD9trsoSMFAMT-08lo/file\n",
            "Reusing existing connection to uc5813019f60b40cea4242020b8c.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 291159106 (278M) [application/zip]\n",
            "Saving to: ‘SD2GAN.zip’\n",
            "\n",
            "SD2GAN.zip          100%[===================>] 277.67M   107MB/s    in 2.6s    \n",
            "\n",
            "2021-05-07 19:05:00 (107 MB/s) - ‘SD2GAN.zip’ saved [291159106/291159106]\n",
            "\n",
            "Loaded Generator from disk.  SD2GAN\n",
            "Generating image\n",
            "you can find the output in output/ folder.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
