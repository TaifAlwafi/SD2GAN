{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SN_SD2GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNwezDXGNnkDSNnmVx2Kb7r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imnawar/SD2GAN/blob/main/SN_SD2GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74O4-0r5asiN"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wYUtNhEa6s_"
      },
      "source": [
        "class SD2GAN():\n",
        "    def __init__(self, **params):\n",
        "        self.img_rows = 28\n",
        "        self.img_cols = 28\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.latent_dim = params['z_dim']\n",
        "        self.dataset = params['dataset']\n",
        "        self.batch_size = params['bs']\n",
        "        self.epochs = params['epochs']\n",
        "\n",
        "        self.optimizer1 = tf.keras.optimizers.Adam(params['lr'], params['beta'])\n",
        "        self.optimizer2 = tf.keras.optimizers.Adam(params['lr_disc2'], params['beta'])\n",
        "\n",
        "        self.sn = self.SN(**params)\n",
        "\n",
        "        if self.dataset == 'mnist': \n",
        "            self.PATH = 'SD2GAN' + '/' + self.dataset +'/' + 'SN'\n",
        "            (self.x_train, self.y_train), (self.x_test, self.y_test) = tf.keras.datasets.mnist.load_data()\n",
        "            self.x_train = self.x_train / 127.5 - 1.\n",
        "            self.x_test = self.x_test / 127.5 - 1.\n",
        "            self.img_rows = self.x_train.shape[1]\n",
        "            self.img_cols = self.x_train.shape[2]\n",
        "            self.channels = 1\n",
        "            self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        elif self.dataset == 'fashion':\n",
        "            self.PATH = 'SD2GAN' + '/' + self.dataset +'/' + 'SN'\n",
        "            (self.x_train, self.y_train), (self.x_test, self.y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "            self.x_train = self.x_train / 127.5 - 1.\n",
        "            self.x_test = self.x_test / 127.5 - 1.\n",
        "            self.img_rows = self.x_train.shape[1]\n",
        "            self.img_cols = self.x_train.shape[2]\n",
        "            self.channels = 1\n",
        "            self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "\n",
        "        #json_file = open(self.PATH + '.json', 'r')\n",
        "        #loaded_model_json = json_file.read()\n",
        "        #json_file.close()\n",
        "        #self.Siamese_net = tf.keras.models.model_from_json(loaded_model_json)\n",
        "        #self.Siamese_net.load_weights(self.PATH + '.h5')\n",
        "\n",
        "\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy', optimizer=self.optimizer1, metrics=['accuracy'])\n",
        "\n",
        "        self.discriminator2 = self.build_discriminator2()\n",
        "        self.discriminator2.compile(loss='binary_crossentropy', optimizer=self.optimizer2, metrics=['accuracy'])\n",
        "\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        self.Siamese_net = self.sn.train(self.generator)\n",
        "\n",
        "        z = tf.keras.layers.Input(shape=(self.latent_dim,))\n",
        "        img = self.generator(z)\n",
        "        imgs1 = tf.keras.layers.Input((self.img_shape))\n",
        "        imgs2 = tf.keras.layers.Input(self.img_shape)\n",
        "        self.discriminator.trainable = False\n",
        "        self.discriminator2.trainable = False\n",
        "        self.Siamese_net.trainable = False\n",
        "        similarity = self.Siamese_net([imgs1, imgs2])\n",
        "        similarity_validity = self.discriminator2(similarity)\n",
        "        validity = self.discriminator(img)\n",
        "\n",
        "        self.combined = tf.keras.models.Model([z, [imgs1, imgs2]], [validity, similarity_validity])\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=self.optimizer1)\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = tf.keras.models.Sequential()\n",
        "        model.add(tf.keras.layers.Dense((128*7*7), input_shape=(self.latent_dim,)))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation('tanh'))\n",
        "        model.add(tf.keras.layers.Reshape((7, 7, 128)))\n",
        "        model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n",
        "        model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same'))\n",
        "        model.add(tf.keras.layers.Activation('tanh'))\n",
        "        model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n",
        "        model.add(tf.keras.layers.Conv2D(1, (5, 5), padding='same'))\n",
        "        model.add(tf.keras.layers.Activation('tanh'))\n",
        "\n",
        "        noise = tf.keras.layers.Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        return tf.keras.models.Model(noise, img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        model = tf.keras.models.Sequential()\n",
        "        model.add(tf.keras.layers.Conv2D(128, (5, 5),padding='same', input_shape=self.img_shape))\n",
        "        model.add(tf.keras.layers.Activation('tanh'))\n",
        "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        model.add(tf.keras.layers.Dense(512))\n",
        "        model.add(tf.keras.layers.Activation('tanh'))\n",
        "        model.add(tf.keras.layers.Dense(1))\n",
        "        model.add(tf.keras.layers.Activation('sigmoid'))\n",
        "\n",
        "        img = tf.keras.layers.Input(shape=self.img_shape,)\n",
        "        validity = model(img)\n",
        "\n",
        "        return tf.keras.models.Model(img, validity)\n",
        "\n",
        "    def build_discriminator2(self):\n",
        "\n",
        "        model = tf.keras.models.Sequential()\n",
        "        model.add(tf.keras.layers.Dense(128, input_shape=(1,), activation=tf.nn.relu))\n",
        "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "        array_sim = tf.keras.layers.Input(shape=(1,))\n",
        "        validity = model(array_sim)\n",
        "\n",
        "        return tf.keras.models.Model(array_sim, validity)\n",
        "\n",
        "    def train(self):\n",
        "        start_time = time.time()\n",
        "        valid = np.ones((self.batch_size, 1))\n",
        "        fake = np.zeros((self.batch_size, 1))\n",
        "        fake_s = np.zeros((int(self.batch_size/2), 1))\n",
        "        real_s = np.ones((int(self.batch_size/2), 1))\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "\n",
        "            idx = np.random.randint(0, self.x_train.shape[0], self.batch_size)\n",
        "            imgs = self.x_train[idx]\n",
        "            noise = np.random.normal(0, 1, (self.batch_size, self.latent_dim))\n",
        "\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "            splited_batch_real = np.split(imgs, 2)\n",
        "            part1_real = splited_batch_real[0]\n",
        "            part2_real = splited_batch_real[1]\n",
        "            sim_real = self.Siamese_net.predict([part1_real, part2_real])\n",
        "\n",
        "            noise2 = np.random.normal(0, 1, (self.batch_size, self.latent_dim))\n",
        "            gen_imgs2 = self.generator.predict(noise2)\n",
        "\n",
        "            splited_batch = np.split(gen_imgs2, 2)\n",
        "            part1 = splited_batch[0]\n",
        "            part2 = splited_batch[1]\n",
        "\n",
        "            sim_fake = self.Siamese_net.predict([part1, part2])\n",
        "            \n",
        "\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            d_loss_real2 = self.discriminator2.train_on_batch(sim_real, real_s)\n",
        "            d_loss_fake2 = self.discriminator2.train_on_batch(sim_fake, fake_s)\n",
        "            d_loss2 = 0.5 * np.add(d_loss_real2, d_loss_fake2)\n",
        "\n",
        "            noise = np.random.normal(0, 1, (self.batch_size, self.latent_dim))\n",
        "            noise2 = np.random.normal(0, 1, (self.batch_size*2, self.latent_dim))\n",
        "            gen_imgs2 = self.generator.predict(noise2)\n",
        "            g_loss = self.combined.train_on_batch([noise, [gen_imgs2[:self.batch_size,:,:,:], gen_imgs2[self.batch_size:,:,:,:]]], valid)\n",
        "\n",
        "            if epoch % 300 == 0:\n",
        "                print (\"%d [D loss: %f, acc.: %.2f%%] [D2 loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], d_loss2[0], 100*d_loss2[1], g_loss[0]))\n",
        "\n",
        "        print(\"Training done in: %s minutes ---\" % ((time.time() - start_time)/60))\n",
        "\n",
        "        model_json = self.generator.to_json()\n",
        "        with open(\"output/generator.json\", \"w\") as json_file:\n",
        "            json_file.write(model_json)\n",
        "        self.generator.save_weights(\"output/generator.h5\")\n",
        "        print(\"Saved Generator to output/\")\n",
        "        r, c = 8, 8\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"output/%d.png\" % epoch)\n",
        "        plt.close()\n",
        "        print(\"Saved generated imgs to output/\")\n",
        "\n",
        "\n",
        "    class SN():\n",
        "        def __init__(self, **params):\n",
        "            self.img_rows = 28\n",
        "            self.img_cols = 28\n",
        "            self.channels = 1\n",
        "            self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "            self.latent_dim = params['z_dim']\n",
        "            self.dataset = params['dataset']\n",
        "            self.batch_size = params['bs']\n",
        "            self.epochs = params['epochs']\n",
        "            self.num_classes = 10\n",
        "\n",
        "        def euclid_dis(self, vects):\n",
        "            x,y = vects\n",
        "            x = tf.cast(x, tf.float32)\n",
        "            y = tf.cast(y, tf.float32)\n",
        "            sum_square = K.sum(K.square(x-y), axis=1, keepdims=True)\n",
        "            return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "        def eucl_dist_output_shape(self, shapes):\n",
        "            shape1, shape2 = shapes\n",
        "            return (shape1[0], 1)\n",
        "\n",
        "        def contrastive_loss(self, y_true, y_pred):\n",
        "            margin = 1\n",
        "            square_pred = K.square(y_pred)\n",
        "            margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
        "            return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
        "\n",
        "        def create_pairs(self, x, digit_indices):\n",
        "            pairs = []\n",
        "            labels = []\n",
        "            \n",
        "            n=min([len(digit_indices[d]) for d in range(self.num_classes)]) -1 \n",
        "            for d in range(self.num_classes):\n",
        "              for i in range(n):\n",
        "                z1, z2 = digit_indices[d][i], digit_indices[d][i+1]\n",
        "                pairs += [[x[z1], x[z2]]]\n",
        "                inc = random.randrange(1, self.num_classes)\n",
        "                dn = (d + inc) % self.num_classes\n",
        "                z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
        "                pairs += [[x[z1], x[z2]]]\n",
        "                labels += [1,0]\n",
        "            return np.array(pairs), np.array(labels)\n",
        "\n",
        "        def create_base_net(self, input_shape):\n",
        "            input = tf.keras.layers.Input(shape = input_shape)\n",
        "            x = tf.keras.layers.Conv2D(4, (5,5), activation = 'tanh')(input)\n",
        "            x = tf.keras.layers.AveragePooling2D(pool_size = (2,2))(x)\n",
        "            x = tf.keras.layers.Conv2D(16, (5,5), activation = 'tanh')(x)\n",
        "            x = tf.keras.layers.AveragePooling2D(pool_size = (2,2))(x)\n",
        "            x = tf.keras.layers.Flatten()(x)\n",
        "            x = tf.keras.layers.Dense(10, activation = 'tanh')(x)\n",
        "            model = tf.keras.models.Model(input, x)\n",
        "            model.summary()\n",
        "            return model\n",
        "\n",
        "        def prepare_data(self, G):\n",
        "            (self.x_train, self.y_train), (self.x_test, self.y_test) = tf.keras.datasets.mnist.load_data()\n",
        "            self.x_train = self.x_train.reshape(self.x_train.shape[0], 28, 28,1)\n",
        "            self.x_test = self.x_test.reshape(self.x_test.shape[0], 28, 28, 1)\n",
        "            self.x_train = self.x_train.astype('float32')\n",
        "            self.x_test = self.x_test.astype('float32')\n",
        "            self.x_train = self.x_train / 127.5 - 1.\n",
        "            self.x_test = self.x_test / 127.5 - 1.\n",
        "\n",
        "            noise = np.random.normal(0, 1, (10000, self.latent_dim))\n",
        "            gen_imgs = G.predict(noise)\n",
        "            X_combined = np.r_[self.x_train, gen_imgs]\n",
        "            noise_labels = np.zeros(10000)\n",
        "            noise_labels += 10\n",
        "            noise_labels = noise_labels.astype('int')\n",
        "            y_combined = np.r_[self.y_train, noise_labels]\n",
        "            self.y_train = y_combined\n",
        "            self.x_train = X_combined\n",
        "\n",
        "            noise = np.random.normal(0, 1, (10000, self.latent_dim))\n",
        "            gen_imgs = G.predict(noise)\n",
        "            X_combined = np.r_[self.x_test, gen_imgs]\n",
        "            noise_labels = np.zeros(10000)\n",
        "            noise_labels += 10\n",
        "            noise_labels = noise_labels.astype('int')\n",
        "            y_combined = np.r_[self.y_test, noise_labels]\n",
        "            self.y_test = y_combined\n",
        "            self.x_test = X_combined\n",
        "\n",
        "            self.input_shape = self.x_train.shape[1:]\n",
        "\n",
        "        def compute_accuracy(self, y_true, y_pred):\n",
        "            pred = y_pred.ravel() < 0.5\n",
        "            return np.mean(pred == y_true)\n",
        "\n",
        "\n",
        "        def accuracy(self, y_true, y_pred):\n",
        "            return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
        "\n",
        "\n",
        "        def train(self, G):\n",
        "            self.prepare_data(G)\n",
        "            # create training+test positive and negative pairs\n",
        "            digit_indices = [np.where(self.y_train == i)[0] for i in range(self.num_classes)]\n",
        "            tr_pairs, tr_y = self.create_pairs(self.x_train, digit_indices)\n",
        "            tr_y = tf.cast(tr_y, tf.float32)\n",
        "\n",
        "            digit_indices = [np.where(self.y_test == i)[0] for i in range(self.num_classes)]\n",
        "            te_pairs, te_y = self.create_pairs(self.x_test, digit_indices)\n",
        "\n",
        "            te_y = tf.cast(te_y, tf.float32)\n",
        "\n",
        "            base_network = self.create_base_net(self.input_shape)\n",
        "\n",
        "            input_a = tf.keras.layers.Input(shape=self.input_shape)\n",
        "            input_b = tf.keras.layers.Input(shape=self.input_shape)\n",
        "\n",
        "            processed_a = base_network(input_a)\n",
        "            processed_b = base_network(input_b)\n",
        "\n",
        "            distance = tf.keras.layers.Lambda(self.euclid_dis,output_shape=self.eucl_dist_output_shape)([processed_a, processed_b])\n",
        "\n",
        "            self.model = tf.keras.models.Model([input_a, input_b], distance)\n",
        "\n",
        "            # train\n",
        "            rms = tf.keras.optimizers.RMSprop()\n",
        "            self.model.compile(loss=self.contrastive_loss, optimizer=rms, metrics=[self.accuracy])\n",
        "            self.model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
        "                      batch_size=128,\n",
        "                      epochs=10)\n",
        "            return self.model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2efPmPutbGLM",
        "outputId": "c2463906-4007-4450-eedf-b8d3dcbd2e11"
      },
      "source": [
        "params = {\n",
        "    'dataset': \"mnist\", # 'mnist' , 'fashion'\n",
        "    'z_dim' : 100, \n",
        "    'lr' : 0.0001, \n",
        "    'lr_disc2' : 0.00009, \n",
        "    'beta' : 0.5, \n",
        "    'bs' : 32, \n",
        "    'epochs' : 30000\n",
        "}\n",
        "# Making output folder\n",
        "try: os.mkdir('output')\n",
        "except: pass\n",
        "gan = SD2GAN(**params)\n",
        "gan.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 4)         104       \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 12, 12, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 16)          1616      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 4,290\n",
            "Trainable params: 4,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "847/847 [==============================] - 56s 64ms/step - loss: 0.1278 - accuracy: 0.8430\n",
            "Epoch 2/10\n",
            "847/847 [==============================] - 55s 64ms/step - loss: 0.1002 - accuracy: 0.8915\n",
            "Epoch 3/10\n",
            "847/847 [==============================] - 54s 64ms/step - loss: 0.0804 - accuracy: 0.9260\n",
            "Epoch 4/10\n",
            "847/847 [==============================] - 54s 64ms/step - loss: 0.0696 - accuracy: 0.9418\n",
            "Epoch 5/10\n",
            "847/847 [==============================] - 54s 64ms/step - loss: 0.0628 - accuracy: 0.9501\n",
            "Epoch 6/10\n",
            "847/847 [==============================] - 54s 64ms/step - loss: 0.0581 - accuracy: 0.9556\n",
            "Epoch 7/10\n",
            "847/847 [==============================] - 54s 64ms/step - loss: 0.0547 - accuracy: 0.9598\n",
            "Epoch 8/10\n",
            "847/847 [==============================] - 54s 64ms/step - loss: 0.0517 - accuracy: 0.9621\n",
            "Epoch 9/10\n",
            "847/847 [==============================] - 54s 64ms/step - loss: 0.0497 - accuracy: 0.9645\n",
            "Epoch 10/10\n",
            "847/847 [==============================] - 54s 64ms/step - loss: 0.0482 - accuracy: 0.9663\n",
            "WARNING:tensorflow:5 out of the last 8475 calls to <function Model.make_train_function.<locals>.train_function at 0x7f85c3a1e9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0 [D loss: 0.743833, acc.: 46.88%] [D2 loss: 0.715233, acc.: 50.00%] [G loss: 1.405678]\n",
            "300 [D loss: 0.700932, acc.: 68.75%] [D2 loss: 0.694406, acc.: 31.25%] [G loss: 3.270535]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}